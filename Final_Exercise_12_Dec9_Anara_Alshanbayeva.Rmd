---
title: "Exercise_12_Dec9_2019_Anara_Alshanbayeva"
output: html_document
---


```{r}
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(muscat))

suppressPackageStartupMessages(library(diffcyt))
suppressPackageStartupMessages(library(rrcov))
suppressPackageStartupMessages(library(CATALYST))
suppressPackageStartupMessages(library(ExperimentHub)) 
suppressPackageStartupMessages(library(moveHMM))
suppressPackageStartupMessages(library(cowplot))
suppressPackageStartupMessages(library(flowCore))
suppressPackageStartupMessages(library(scater))
suppressPackageStartupMessages(library(SingleCellExperiment))
suppressPackageStartupMessages(library(ExperimentHub))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(Seurat))
suppressPackageStartupMessages(library(UpSetR))
suppressPackageStartupMessages(library(PCAtools))
suppressPackageStartupMessages(library(mclust))
suppressPackageStartupMessages(library(clue))
suppressPackageStartupMessages(library(plyr))

``` 

#### Question 1. 
#### Grab a well-known dataset, the Zheng 10x PBMC pre-sorted dataset,
#### from ExperimentHub (see code below). Explore basic properties of this dataset, 
#### including the number cells of each subpopulation (see the phenoid column of the colData), 
#### the depth of sequencing by subpopulation and other aspects you can think of. 
#### Re-investigate the filtering (some was already) by plotting 
#### the percentage of mitochondrial reads versus the total number of reads. 
#### If appropriate, additionally filter any outlier cells.
```{r}
eh <- ExperimentHub()
sce <- eh[["EH1532"]]
rownames(sce) <- paste0(rowData(sce)$id, "_", rowData(sce)$symbol)
sce
``` 

#### Investigating the data: 
#### We can extract the subpopulations' names through sce@colData:
```{r}
populations=sce@colData@listData[["phenoid"]]
populations2=as.data.frame(sce@colData@listData[["phenoid"]])
 unique(populations2)
``` 
#### Below we can see the number of cells in each of these populations: 
```{r}
b_cell=sum(populations=="b.cells",value=TRUE)  
naive_cytotoxic=sum(populations=="naive.cytotoxic",value=TRUE)  
cd14_monocytes=sum(populations=="cd14.monocytes",value=TRUE)  
regulatory_t=sum(populations=="regulatory.t",value=TRUE)  
cd4_t_helper=sum(populations=="cd4.t.helper",value=TRUE)  
cd56_nk=sum(populations=="cd56.nk",value=TRUE)  
memory_t=sum(populations=="memory.t",value=TRUE)  
naive_t=sum(populations=="naive.t",value=TRUE)  

b_cell
naive_cytotoxic
cd14_monocytes
regulatory_t
cd4_t_helper
cd56_nk
memory_t
naive_t
``` 

#### We can also check the total number of reads/Sequencing depth for each cell type: 
```{r}
total_counts=sce@colData@listData[["total_counts"]]
bcell_depth=sum(total_counts[1:499])
naive_cytotoxic_depth=sum(total_counts[500:897])
cd14_monocytes_depth=sum(total_counts[898:1497])
regulator_t_cell=sum(total_counts[1498:1995])
cd4_t_helper_depth=sum(total_counts[1996:2395])
cd56nk_depth=sum(total_counts[2396:2995])
memory_t_depth=sum(total_counts[2996:3495])
naive_t_depth=sum(total_counts[3496:3908])

``` 

#### Plotting percentage of mitochondrial genes mapped vs. total counts: 
```{r}
(mito <- grep("MT-", rownames(sce), value = TRUE))
df <- perCellQCMetrics(sce, subsets=list(Mito=mito))
df 

discard.mito <- isOutlier(df$subsets_Mito_percent, type="higher")
summary(discard.mito)

plot(df$sum, df$subsets_Mito_percent, log="x",
     xlab="Total count", ylab='Mitochondrial %')
abline(h=attr(discard.mito, "thresholds")["higher"], col="red")

``` 
#### Keeping the columns we DON'T want to discard (and removing all cells that have high mitochnodnrial gene content):
```{r}
filtered <- sce[,!discard.mito]
sce=filtered 
``` 

#### After filtering, we need to normalize our data as well: 
```{r}
library(scran)
clusters <- quickCluster(sce)
sce <- computeSumFactors(sce, cluster=clusters) 
sce <- logNormCounts(sce)
``` 
#### Question 2. 
#### Identify “features of interest”, which usually means highly variable genes.
#### There are various ways to do this (e.g., Seurat’s FindVariableFeatures or scran’s modelGeneVar).
#### Select features in at least two ways (say, 1000-2000 genes) and make an upset plot to compare the lists.

#### Quantifying per gene variation by variance of the log-counts: 
#### Variance in the PBMC data set as a function of the mean. 
#### Each point represents a gene while the red line represents the trend fitted to all genes.
```{r}
suppressPackageStartupMessages(library(scran))
dec.pbmc <- modelGeneVar(sce)
fit.pbmc <- metadata(dec.pbmc)
plot(fit.pbmc$mean, fit.pbmc$var, xlab="Mean of log-expression",
     ylab="Variance of log-expression")
curve(fit.pbmc$trend(x), col="red", add=TRUE, lwd=2)
``` 
#### Ordering by most interesting genes for inspection.
```{r}
dec.pbmc[order(dec.pbmc$bio, decreasing=TRUE),] 
order_dec_pbmc=dec.pbmc[order(dec.pbmc$bio, decreasing=TRUE),] 
FDR=as.data.frame(order_dec_pbmc@listData[["FDR"]])
FDR_0.05_method1 <- subset(FDR, order_dec_pbmc@listData[["FDR"]]< 0.05 )


``` 
#### Quantifying per gene variation by Squared coefficient of variation:
```{r}
dec.cv2.pbmc <- modelGeneCV2(sce)
fit.cv2.pbmc <- metadata(dec.cv2.pbmc)
plot(fit.cv2.pbmc$mean, fit.cv2.pbmc$cv2, log="xy")
curve(fit.cv2.pbmc$trend(x), col="red", add=TRUE, lwd=2)
``` 
#### The deviation for each gene from the trend: 
```{r}
dec.cv2.pbmc[order(dec.cv2.pbmc$ratio, decreasing=TRUE),]
``` 
#### Taking the top 1000 genes based on the variance of the log-counts:  
```{r}
hvg.pbmc.var <- getTopHVGs(dec.pbmc, n=2000)
str(hvg.pbmc.var)
``` 
#### Taking top genes based on significance: our HVGs are defined as all genes that have adjusted  p-values below 0.05. We can see around 699 genes pass this threshold.
```{r}
hvg.pbmc.var.2 <- getTopHVGs(dec.pbmc, fdr.threshold = 0.05)
``` 

####Question 3. Re-calculate the low dimensional projection using your preferred set of selected features 
####and produce some visualizations. For example, after re-running PCA, use the scater package to run the UMAP 
####algorithm. Make multiple plots of the UMAP coordinates according to cell type (this is known in advance for 
####this dataset), depth of sequencing and anything else you might find appropriate.
```{r}
suppressPackageStartupMessages(library(scater))
sce=runPCA(sce,subset_row=hvg.pbmc.var)

percent.var <- attr(reducedDim(sce), "percentVar")
chosen.elbow <- PCAtools::findElbowPoint(percent.var)
chosen.elbow
plot(percent.var, xlab="PC", ylab="Variance explained (%)")
abline(v=chosen.elbow, col="red")
reducedDim(sce, "PCA") <- reducedDim(sce, "PCA")[,1:10]
ncol(reducedDim(sce, "PCA"))
reducedDim(sce, "PCA_10") <- reducedDim(sce, "PCA")[,1:10]
reducedDimNames(sce)
plotReducedDim(sce, dimred="PCA",colour_by = "phenoid")

sce<- runUMAP(sce, dimred="PCA")
reducedDimNames(sce)
dim(reducedDim(sce, "UMAP"))
plotReducedDim(sce, dimred="UMAP",colour_by = "phenoid")
plotReducedDim(sce, dimred="UMAP",colour_by = "log10_total_features")
plotReducedDim(sce, dimred="UMAP",colour_by = "log10_total_counts")
``` 

####Question 4. Run at least 2 algorithms to cluster the data and make some comparisons. 
####One should be graph-based clustering as this seems to perform well, generally speaking. 
####Calculate the F1 score for each cell type (solve_LSAP in the clue package may be useful for matching 
####of clsuters to true populations) and the adjusted rand index (adjustedRandIndex in the mclust package, 
####for example) for an overall score. What cell types are more difficult to separate with clustering?
#### Run one of the algorithms at different numbers of clusters and plot a curve of the performance 
####(e.g., adjusted rand index) as a function of the number of clusters.

#### First of the 2 algorithms for clustering - the graph based clustering. 
#### After the clustering, we assign this graph based clustering results back into the singlecellexperiment & make a t-SNE plot:  
```{r}
suppressPackageStartupMessages(library(scran))
g <- buildSNNGraph(sce, k=18, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
plotReducedDim(sce, "PCA", colour_by="cluster")
``` 
#### Second of the 2 algorithms for clustering - K-means custering: 
```{r}
sce1=sce
clust.kmeans <- kmeans(reducedDim(sce, "PCA"), centers=7)
table(clust.kmeans$cluster)
sce1$cluster <- factor(clust.kmeans$cluster)
plotReducedDim(sce1, "TSNE", colour_by="cluster") 
``` 
#### Calculating the adjusted Rand Index of the clusters generated by PCA & k-means: 
```{r}
adjustedRandIndex(sce$cluster,clust.kmeans$cluster)

``` 

#### Run one of the algorithms at different numbers of clusters and plot a curve of the performance 
####(e.g., adjusted rand index) as a function of the number of clusters.
```{r}
suppressPackageStartupMessages(library(scran))
g <- buildSNNGraph(sce, k=2, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
k2value=adjustedRandIndex(sce$cluster,clust.kmeans$cluster)
k2clusters=nrow(unique(as.data.frame(clust)))

g <- buildSNNGraph(sce, k=3, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
k3value=adjustedRandIndex(sce$cluster,clust.kmeans$cluster)
k3clusters=nrow(unique(as.data.frame(clust)))

g <- buildSNNGraph(sce, k=4, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
k4value=adjustedRandIndex(sce$cluster,clust.kmeans$cluster)
k4clusters=nrow(unique(as.data.frame(clust)))


g <- buildSNNGraph(sce, k=5, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
k5value=adjustedRandIndex(sce$cluster,clust.kmeans$cluster)
k5clusters=nrow(unique(as.data.frame(clust)))

g <- buildSNNGraph(sce, k=6, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
k6value=adjustedRandIndex(sce$cluster,clust.kmeans$cluster)
k6clusters=nrow(unique(as.data.frame(clust)))

g <- buildSNNGraph(sce, k=7, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
k7value=adjustedRandIndex(sce$cluster,clust.kmeans$cluster)
k7clusters=nrow(unique(as.data.frame(clust)))


g <- buildSNNGraph(sce, k=8, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
k8value=adjustedRandIndex(sce$cluster,clust.kmeans$cluster)
k8clusters=nrow(unique(as.data.frame(clust)))


g <- buildSNNGraph(sce, k=9, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
k9value=adjustedRandIndex(sce$cluster,clust.kmeans$cluster)
k9clusters=nrow(unique(as.data.frame(clust)))


g <- buildSNNGraph(sce, k=12, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
k12value=adjustedRandIndex(sce$cluster,clust.kmeans$cluster)
k12clusters=nrow(unique(as.data.frame(clust)))

g <- buildSNNGraph(sce, k=13, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
k13value=adjustedRandIndex(sce$cluster,clust.kmeans$cluster)
k13clusters=nrow(unique(as.data.frame(clust)))

g <- buildSNNGraph(sce, k=15, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
k15value=adjustedRandIndex(sce$cluster,clust.kmeans$cluster)
k15clusters=nrow(unique(as.data.frame(clust)))

g <- buildSNNGraph(sce, k=20, use.dimred = 'PCA')
clust <- igraph::cluster_walktrap(g)$membership
table(clust)
suppressPackageStartupMessages(library(scater))
sce$cluster <- factor(clust)
k20value=adjustedRandIndex(sce$cluster,clust.kmeans$cluster)
k20clusters=nrow(unique(as.data.frame(clust)))

values=data.frame(k2value,k3value,k4value,k5value,k6value,k7value,k8value,k9value,k12value,k13value,k15value,k20value)
clusters=data.frame(k2clusters,k3clusters,k4clusters,k5clusters,k6clusters,k7clusters,k8clusters,k9clusters,k12clusters,k13clusters,k15clusters,k20clusters)
values=as.matrix(values)
clusters=as.matrix(clusters)
plot(clusters,values)

``` 

#### When the cluster numbers are changed in as in the plot above (from k=2 to k=20), the ####AdjustedRandIndex values are changed accordingly. As we can see, when the number of clusters ####reaches the biological/expected number of clusters, the AdjustedRandIndex value goes close to ####0.48-0.5. 

#### The cell types that are difficult to separate by clustering are: "cd4.t.helper cells"" and "regulatory t.cells". 



























